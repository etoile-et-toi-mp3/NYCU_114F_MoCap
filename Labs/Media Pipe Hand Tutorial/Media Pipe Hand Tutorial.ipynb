{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Install and Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mediapipe as mp\n",
    "import cv2\n",
    "import time\n",
    "import math\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpDraw = mp.solutions.drawing_utils #Call the drawing tool\n",
    "mpHands = mp.solutions.hands #Call the hand tracking tool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Two-Hand Tracking\n",
    "\n",
    " <img src=https://i.imgur.com/qpRACer.png />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Setup up the hand tracking module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "hands = mpHands.Hands(  \n",
    "    static_image_mode=False, #Image or Video (True: still image, False: steam mode)\n",
    "    #model_complexity=0,#0->compact model(fast speed)，1->full mode(slow speed)\n",
    "    max_num_hands=2, #How many hands are allowed to be recognized\n",
    "    min_detection_confidence=0.5, #confidence for hand detection\n",
    "    min_tracking_confidence=0.5 #confidence for hand tracking\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cap = cv2.VideoCapture(5)\n",
    "# cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)\n",
    "# cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)\n",
    "\n",
    "# while cap.isOpened(): #Is camera open or not\n",
    "#     stime=time.time()\n",
    "#     ret, frame = cap.read() #read camera data\n",
    "#     h, w, c = frame.shape #get resolution(width/height) of the camera\n",
    "#     frame=cv2.flip(frame,1) #flip image：-1:up and down、0: up and down, left and right、1:  left and right\n",
    "#     imgRGB = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB) #convert color channel from BGR(opencv) to RGB(mediapipe)\n",
    "#     results = hands.process(imgRGB) #tracking hands and get the results\n",
    "    \n",
    "#     if results.multi_hand_landmarks: #If find any hand\n",
    "#         for i in range(len(results.multi_handedness)): #get the numbers of detected hands\n",
    "#             thisHandType=results.multi_handedness[i].classification[0].label #get properties of the detected hand      \n",
    "#             thisHand=results.multi_hand_landmarks[i] #get hand label information\n",
    "#             mpDraw.draw_landmarks(frame, thisHand, mpHands.HAND_CONNECTIONS) #draw tools\n",
    "#             #draw hands in the screen\n",
    "#             for id, lm in enumerate(thisHand.landmark): #id=number,lm=coordinate               \n",
    "#                 hx, hy = int(lm.x * w), int(lm.y * h) #get coordinate of the joint\n",
    "#                 cv2.circle(frame, (hx, hy), 5, (255, 0, 0), cv2.FILLED) #make circles with blue color\n",
    "#                 cv2.putText(frame,str(id),(hx,hy), cv2.FONT_HERSHEY_PLAIN, 1, (255, 0, 255), 1)\n",
    "#                 if id==0:\n",
    "#                     cv2.putText(frame,thisHandType,(hx,hy-30), cv2.FONT_HERSHEY_PLAIN, 2, (0, 255, 0), 2)            \n",
    "#     etime=time.time()\n",
    "#     fps=round(1/(etime-stime),2)\n",
    "#     cv2.putText(frame,\"FPS:\" + str(fps),(10,50), cv2.FONT_HERSHEY_PLAIN, 3, (0, 0, 255), 3)\n",
    "#     cv2.imshow('Webcam',frame) #display results on the screen\n",
    "#     key=cv2.waitKey(1) #waitting for user's inputs\n",
    "#     if key==ord('a'):  # 'a': capture photo\n",
    "#         cv2.imwrite('webcam.jpg',frame) # save file\n",
    "#     if key==ord('q'):  #'q': quit\n",
    "#         break\n",
    "# cap.release()\n",
    "# cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hand Pose Recognition\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setup the Hand tracking module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "hands = mpHands.Hands(  \n",
    "    static_image_mode=False, #Image or Video (True: still image, False: stream mode)\n",
    "    model_complexity=0,#0->compact model(fast speed)，1->full mode(slow speed)\n",
    "    max_num_hands=2,  #How many hands are allowed to be recognized\n",
    "    min_detection_confidence=0.7, #confidence for hand detection\n",
    "    min_tracking_confidence=0.5 #confidence for hand tracking\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "AngleTH=130 #threshold(TH) angle: the joint in range of motion\n",
    "def findAngleF(a,b,c):    \n",
    "    ang = math.degrees(math.atan2(c[2]-b[2], c[1]-b[1]) - math.atan2(a[2]-b[2], a[1]-b[1]))\n",
    "    if ang<0 :\n",
    "      ang=ang+360\n",
    "    if ang >= 360- ang:\n",
    "        ang=360-ang\n",
    "    return round(ang,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cap = cv2.VideoCapture(5)\n",
    "# cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)\n",
    "# cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)\n",
    "\n",
    "# while cap.isOpened(): #Is camera open or not\n",
    "#     stime=time.time()\n",
    "#     ret, frame = cap.read() #read camera data\n",
    "#     h, w, c = frame.shape  #get resolution(width/height) of the camera\n",
    "#     frame=cv2.flip(frame,1) #flip image：-1:up and down、0: up and down, left and right、1:  left and right\n",
    "#     imgRGB = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB) #convert color channel from BGR(opencv) to RGB(mediapipe)\n",
    "#     results = hands.process(imgRGB) #tracking hands and get the results\n",
    "    \n",
    "#     zero_xs = [-1, -1]\n",
    "#     gesture = [None, None]\n",
    "#     gesture_names = [\"Rock\", \"Scissors\", \"Paper\"]\n",
    "#     wrist_position = [None, None]\n",
    "    \n",
    "#     if results.multi_hand_landmarks: #If there is any hand available\n",
    "#         for i in range(len(results.multi_handedness)): #get the numbers of detected hands\n",
    "#             thisHandType=results.multi_handedness[i].classification[0].label #get properties of the detected hand          \n",
    "#             thisHand=results.multi_hand_landmarks[i] #get hand label information \n",
    "#             mpDraw.draw_landmarks(frame, thisHand, mpHands.HAND_CONNECTIONS) #draw tools\n",
    "#             thisHandLMList = []\n",
    "#             for id, lm in enumerate(thisHand.landmark): #id=number,lm=coordinate                  \n",
    "#                 thisHandLMList.append([id, lm.x, lm.y,lm.z])\n",
    "#                 hx, hy = int(lm.x * w), int(lm.y * h) #get coordinate of the joint\n",
    "#                 cv2.circle(frame, (hx, hy), 5, (255, 0, 0), cv2.FILLED)  #make circles with blue color\n",
    "#                 cv2.putText(frame,str(id),(hx,hy), cv2.FONT_HERSHEY_PLAIN, 1, (255, 0, 255), 1)\n",
    "#                 if id==0:\n",
    "#                     cv2.putText(frame,thisHandType,(hx,hy-30), cv2.FONT_HERSHEY_PLAIN, 2, (0, 255, 0), 2)   \n",
    "#                     wrist_position[i] = (hx, hy)\n",
    "#             zero_xs[i] = thisHandLMList[0]\n",
    "#             finger=[0,0,0,0,0]\n",
    "#             if (findAngleF(thisHandLMList[0],thisHandLMList[3],thisHandLMList[4])>AngleTH):\n",
    "#                 finger[0]=1\n",
    "#             if (findAngleF(thisHandLMList[0],thisHandLMList[6],thisHandLMList[8])>AngleTH):\n",
    "#                 finger[1]=1\n",
    "#             if (findAngleF(thisHandLMList[0],thisHandLMList[10],thisHandLMList[12])>AngleTH):\n",
    "#                 finger[2]=1\n",
    "#             if (findAngleF(thisHandLMList[0],thisHandLMList[14],thisHandLMList[16])>AngleTH):\n",
    "#                 finger[3]=1\n",
    "#             if (findAngleF(thisHandLMList[0],thisHandLMList[18],thisHandLMList[20])>AngleTH):\n",
    "#                 finger[4]=1\n",
    "#             #print(finger)\n",
    "\n",
    "#             #-----------------Recognizing hand gestures------------------------\n",
    "#             text=0#     Thumb,Index,Middle,Ring,Little finger\n",
    "#             if (finger==[0,0,0,0,0]):\n",
    "#                 text=0\n",
    "#             if (finger==[0,1,1,0,0]):\n",
    "#                 text=1\n",
    "#             if (finger==[1,1,1,1,1]):\n",
    "#                 text=2\n",
    "#             #           Image   text   coordinate       font style   font size   font color  thickness\n",
    "#             # cv2.putText(frame, textx, (0, 200), cv2.FONT_HERSHEY_PLAIN, 5  , (255, 0, 0), 5) #put text to the screen\n",
    "#             gesture[i] = text\n",
    "#             if wrist_position is not None:\n",
    "#                 cv2.putText(frame, gesture_names[text], (wrist_position[i][0] - 40, wrist_position[i][1] + 60), cv2.FONT_HERSHEY_PLAIN, 3, (0, 255, 255), 3)\n",
    "\n",
    "\n",
    "#     if zero_xs[0] != -1 and zero_xs[1] != -1 :\n",
    "#         # two hands are detected\n",
    "#         if zero_xs[0] > zero_xs[1]:\n",
    "#             gesture[0], gesture[1] = gesture[1], gesture[0]\n",
    "\n",
    "#         if gesture[0] == gesture[1]:\n",
    "#             cv2.putText(frame, \"draw\", (0, 200), cv2.FONT_HERSHEY_PLAIN, 5  , (255, 0, 0), 5) #put text to the screen\n",
    "#         elif (gesture[0] + 1) % 3 == gesture[1]:\n",
    "#             cv2.putText(frame, \"left win!\", (0, 200), cv2.FONT_HERSHEY_PLAIN, 5  , (255, 0, 0), 5) #put text to the screen\n",
    "#         else:\n",
    "#             cv2.putText(frame, \"right win!\", (0, 200), cv2.FONT_HERSHEY_PLAIN, 5  , (255, 0, 0), 5) #put text to the screen\n",
    "\n",
    "#     etime=time.time()\n",
    "#     fps=round(1/(etime-stime),2)\n",
    "#     cv2.putText(frame,\"FPS:\" + str(fps),(10,50), cv2.FONT_HERSHEY_PLAIN, 3, (0, 0, 255), 3)\n",
    "#     cv2.imshow('Webcam',frame) #display results on the screen\n",
    "#     key=cv2.waitKey(1) #waitting for user's inputs\n",
    "#     if key==ord('a'):   # 'a': capture photo\n",
    "#         cv2.imwrite('webcam.jpg',frame) # save file\n",
    "#     if key==ord('q'):  #'q': quit\n",
    "#         break\n",
    "# cap.release()\n",
    "# cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interactive Game\n",
    "\n",
    "#Mushroom Catching Game Instructions\n",
    "\n",
    "#Please prepare an audio file 'eat.mp3' for the sound effect when catching is successful.\n",
    "\n",
    "#Please prepare two image files 'b.jpg' and 'm.jpg'.\n",
    "\n",
    "#The image processing in the program will remove the white background and resize the images, so please use images with a white background or in PNG format.\n",
    "\n",
    "#The background removal settings can be found on line 59, inside the 'cv2.threshold' function. Pixels with values greater than 'thresh' will be deleted.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import time\n",
    "import mediapipe as mp\n",
    "import random\n",
    "import math\n",
    "import numpy as np\n",
    "import playsound #pip3 install playsound==1.2.2 #\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpDraw = mp.solutions.drawing_utils #Call the drawing tool\n",
    "mpHands = mp.solutions.hands #Call the hand tracking tool\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Call the hand recognition tool within the hand tracking tool\n",
    "hands = mpHands.Hands(  \n",
    "    static_image_mode=False,  #Image or Video (True: still image, False: stream mode)\n",
    "    #model_complexity=0,#0->compact model(fast speed)，1->full mode(slow speed)\n",
    "    max_num_hands=1, #How many hands are allowed to be recognized\n",
    "    min_detection_confidence=0.5, #confidence for hand detection\n",
    "    min_tracking_confidence=0.5  #confidence for hand tracking\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load object image (white background can be removed)\n",
    "ObjSizeX,ObjSizeY=80,80\n",
    "BucketSizeX,BucketSizeY=180,80\n",
    "Obj = cv2.resize(cv2.imread('images/W1/l.png'),(ObjSizeX,ObjSizeY)) #Object image\n",
    "#Load basket image\n",
    "Bucket = cv2.resize(cv2.imread('images/W1/b.png'),(BucketSizeX,BucketSizeY)) #Object image\n",
    "#Grabbing Status\n",
    "catchObj=False\n",
    "#Whether to generate a New Object\n",
    "NewObj=True\n",
    "#Obj Starting Position\n",
    "x,y=0,0\n",
    "#Score\n",
    "Score=0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "AngleTH=130 #Determine Opening Angle\n",
    "def findAngleF(a,b,c):    \n",
    "    ang = math.degrees(math.atan2(c[2]-b[2], c[1]-b[1]) - math.atan2(a[2]-b[2], a[1]-b[1]))\n",
    "    if ang<0 :\n",
    "        ang=ang+360\n",
    "    if ang >= 360- ang:\n",
    "        ang=360-ang\n",
    "    return round(ang,2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drawing: Placing the object at a specific position on the background, removing the white border\n",
    "def addPng(ax,ay,bg,png):\n",
    "    global NewObj\n",
    "    pngY,pngX,channels = png.shape        \n",
    "    bgY,bgX,channels = bg.shape\n",
    "    if (ax+pngX<=bgX and ax>=0) and (ay+pngY<=bgY and ay>=0):\n",
    "        roi = bg[ay:ay+pngY, ax:ax+pngX ] #Placement Position\n",
    "        #1. Create a black PNG portion as a mask\n",
    "        pnggray = cv2.cvtColor(png,cv2.COLOR_BGR2GRAY)\n",
    "        ret, mask = cv2.threshold(pnggray, thresh=230, maxval=255, type=cv2.THRESH_BINARY) #Less than thresh becomes 0, the rest become maxval.\n",
    "        mask_inv = cv2.bitwise_not(mask) #Inverse\n",
    "        #cv2.imshow('mask',mask_inv)\n",
    "        #cv2.waitKey(0)\n",
    "        #2.get the background area\n",
    "        bg_roi = cv2.bitwise_and(roi,roi,mask = mask) # Extract the remaining background\n",
    "        #cv2.imshow('mask',bg_roi)\n",
    "        #cv2.waitKey(0)\n",
    "        #3.get the Logo area\n",
    "        png_roi = cv2.bitwise_and(png,png,mask = mask_inv) #Retrieve the actual display area\n",
    "        #cv2.imshow('mask',png_roi)\n",
    "        #cv2.waitKey(0)\n",
    "        #4.making the final presenation\n",
    "        dst = cv2.add(bg_roi,png_roi)\n",
    "        bg[ay:ay+pngY, ax:ax+pngX ] = dst\n",
    "        return bg\n",
    "    else:\n",
    "        NewObj=True\n",
    "        return bg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Detecting Palm Status\n",
    "def fist(frame):\n",
    "    imgRGB = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB) #convert color channel from BGR(opencv) to RGB(mediapipe)\n",
    "    h, w, c = frame.shape #get resolution(width/height) of the camera\n",
    "    results = hands.process(imgRGB)  #tracking hands and get the results\n",
    "\n",
    "    if results.multi_hand_landmarks: #If there is any hand available\n",
    "        for i in range(len(results.multi_handedness)): #get the numbers of detected hands\n",
    "            thisHandType=results.multi_handedness[i].classification[0].label #get properties of the detected hand            \n",
    "            thisHand=results.multi_hand_landmarks[i] #get hand label information\n",
    "            mpDraw.draw_landmarks(frame, thisHand, mpHands.HAND_CONNECTIONS) #draw tools\n",
    "            thisHandLMList = []\n",
    "            for id, lm in enumerate(thisHand.landmark): #id=number,lm=coordinate                 \n",
    "                thisHandLMList.append([id, lm.x, lm.y,lm.z])\n",
    "                hx, hy = int(lm.x * w), int(lm.y * h)  #get coordinate of the joint\n",
    "                cv2.circle(frame, (hx, hy), 5, (255, 0, 0), cv2.FILLED) #make circles with blue color\n",
    "                cv2.putText(frame,str(id),(hx,hy), cv2.FONT_HERSHEY_PLAIN, 1, (255, 0, 255), 1)\n",
    "                if id==0:\n",
    "                    cv2.putText(frame,thisHandType,(hx,hy-30), cv2.FONT_HERSHEY_PLAIN, 2, (0, 255, 0), 2)            \n",
    "            finger=[0,0,0,0,0]\n",
    "            if (findAngleF(thisHandLMList[0],thisHandLMList[3],thisHandLMList[4])>AngleTH):\n",
    "                finger[0]=1\n",
    "            if (findAngleF(thisHandLMList[0],thisHandLMList[6],thisHandLMList[8])>AngleTH):\n",
    "                finger[1]=1\n",
    "            if (findAngleF(thisHandLMList[0],thisHandLMList[10],thisHandLMList[12])>AngleTH):\n",
    "                finger[2]=1\n",
    "            if (findAngleF(thisHandLMList[0],thisHandLMList[14],thisHandLMList[16])>AngleTH):\n",
    "                finger[3]=1\n",
    "            if (findAngleF(thisHandLMList[0],thisHandLMList[18],thisHandLMList[20])>AngleTH):\n",
    "                finger[4]=1\n",
    "            #print(finger)\n",
    "\n",
    "            totalFingers=finger.count(1)    \n",
    "            x1,y1=np.amin(np.array(thisHandLMList)[:,1]),np.amin(np.array(thisHandLMList)[:,2])\n",
    "            x2,y2=np.amax(np.array(thisHandLMList)[:,1]),np.amax(np.array(thisHandLMList)[:,2])  \n",
    "            return totalFingers,x1,y1,x2,y2\n",
    "    else:\n",
    "        return None,None,None,None,None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== GAME STATISTICS ===\n",
      "Final Score: 0\n",
      "Game Duration: 30 seconds\n",
      "========================\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(5)\n",
    "cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)\n",
    "cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)\n",
    "\n",
    "# Example after you already have your frame and window name\n",
    "window_name = \"Mushroom Catching Game\"\n",
    "cv2.namedWindow(window_name, cv2.WINDOW_NORMAL)\n",
    "\n",
    "screen_w, screen_h = 1280, 720  # or use pyautogui.size()\n",
    "x = (screen_w) // 4\n",
    "y = (screen_h) // 4\n",
    "cv2.moveWindow(window_name, x, y)\n",
    "cv2.resizeWindow(window_name, 1280, 760)\n",
    "\n",
    "start_time = None\n",
    "elapsed_time = None\n",
    "game_time = 30\n",
    "\n",
    "while cap.isOpened():  #Is camera open or not\n",
    "    stime=time.time()\n",
    "    ret, frame = cap.read() #read camera data\n",
    "    h, w, c = frame.shape #get resolution(width/height) of the camera\n",
    "    frame=cv2.flip(frame,1) #flip image：-1:up and down、0: up and down, left and right、1:  left and right\n",
    "    \n",
    "    if start_time is None:\n",
    "        start_time = time.time()\n",
    "    \n",
    "    elapsed_time = time.time() - start_time\n",
    "    \n",
    "    if elapsed_time - game_time > 0:\n",
    "        break\n",
    "    \n",
    "    cv2.putText(frame, f\"Time: {int(game_time-elapsed_time)}s\", (w - 300, 140), cv2.FONT_HERSHEY_PLAIN, 3, (255, 255, 0), 3)\n",
    "    \n",
    "    #Detecting Grasp\n",
    "    totalFingers,hx1,hy1,hx2,hy2=fist(frame)\n",
    "    if not (totalFingers==None): #Hand Detected\n",
    "        if totalFingers<=1: #Fist Clenched\n",
    "            #Get Palm Area\n",
    "            #print(hx1,hy1,hx2,hy2)\n",
    "            if ((x+ObjSizeX//2)>=hx1*w and (x+ObjSizeX//2)<=hx2*w and (y+ObjSizeY//2)>=hy1*h and (y+ObjSizeY//2)<=hy2*h):#If the object is within the palm\n",
    "                #print(\"Catched\")\n",
    "                catchObj=True\n",
    "            else:\n",
    "                #print(\"No\")\n",
    "                catchObj=False\n",
    "        else:\n",
    "            catchObj=False\n",
    "    else:\n",
    "        catchObj=False\n",
    "\n",
    "#Basket is in the middle at the bottom\n",
    "    BucketX=round((w-BucketSizeX)/2)#middle\n",
    "    BucketY=round(h-BucketSizeY/2-50)#bottom\n",
    "    frame=addPng(BucketX,BucketY,frame,Bucket)    \n",
    "\n",
    "    if catchObj :#Object Grabbing Process\n",
    "        #Object follows Palm\n",
    "        x,y=round(((hx1+hx2)*w-ObjSizeX)//2),round(((hy1+hy2)*h-ObjSizeY)//2)\n",
    "        frame=addPng(x,y,frame,Obj)\n",
    "        #Determine if the object is inside the basket----------------------------------------\n",
    "        if ((x+ObjSizeX//2)>=BucketX and (x+ObjSizeX//2)<=BucketX+BucketSizeX and (y+ObjSizeY//2)>=BucketY and (y+ObjSizeY//2)<=BucketY+BucketSizeY):\n",
    "            Score=Score+1\n",
    "            print(\"Score=\" + str(Score))\n",
    "            NewObj=True\n",
    "            catchObj=False\n",
    "            playsound.playsound(\"eat.mp3\")\n",
    "\n",
    "\n",
    "            #Reset Coordinates\n",
    "            x,y=random.randint(10,w-ObjSizeX-10) ,5\n",
    "    elif(NewObj==False):#Freefall Process        \n",
    "        y=y+5\n",
    "        frame=addPng(x,y,frame,Obj)\n",
    "    else:#Generate New Object Process\n",
    "        x,y=random.randint(10,w-ObjSizeX-10) ,5\n",
    "        NewObj=False  \n",
    "    etime=time.time()\n",
    "    fps=round(1/(etime-stime),2)\n",
    "    cv2.putText(frame, \"Get \" + str(Score) , (10, 70), cv2.FONT_HERSHEY_PLAIN, 3, (255, 0, 255), 3)    \n",
    "    cv2.putText(frame, \"FPS \" + str(fps) , (w-300, 70), cv2.FONT_HERSHEY_PLAIN, 3, (0, 255, 255), 3)    \n",
    "    cv2.imshow(window_name, frame)\n",
    "    key=cv2.waitKey(1) #Waiting for User Keyboard Input\n",
    "    if key==ord('a'):  #'a': capture photo\n",
    "        cv2.imwrite('webcam.jpg',frame) #save file\n",
    "    if key==ord('q'):  #'q': quit\n",
    "        break\n",
    "\n",
    "game_over_start = time.time()\n",
    "while time.time() - game_over_start < 3.0:\n",
    "    ret, frame = cap.read()\n",
    "    if ret:\n",
    "        frame = cv2.flip(frame, 1)\n",
    "        # Display game over screen\n",
    "        cv2.putText(frame, \"GAME OVER!\", (screen_w//2 - 400, screen_h//2 - 100), \n",
    "                    cv2.FONT_HERSHEY_PLAIN, 8, (0, 0, 255), 8)\n",
    "        cv2.putText(frame, f\"Final Score: {Score}\", (screen_w//2 - 300, screen_h//2), \n",
    "                    cv2.FONT_HERSHEY_PLAIN, 5, (255, 255, 255), 5)\n",
    "        cv2.putText(frame, \"Thanks for playing!\", (screen_w//2 - 350, screen_h//2 + 100), \n",
    "                    cv2.FONT_HERSHEY_PLAIN, 4, (0, 255, 0), 4)\n",
    "        cv2.imshow(window_name, frame)\n",
    "        cv2.waitKey(33)  # ~30 FPS\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# Print final game statistics\n",
    "print(f\"\\n=== GAME STATISTICS ===\")\n",
    "print(f\"Final Score: {Score}\")\n",
    "print(f\"Game Duration: {game_time} seconds\")\n",
    "print(f\"========================\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mocap",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
