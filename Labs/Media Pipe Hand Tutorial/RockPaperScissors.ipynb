{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mediapipe as mp\n",
    "import cv2\n",
    "import time\n",
    "import math\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpDraw = mp.solutions.drawing_utils #Call the drawing tool\n",
    "mpHands = mp.solutions.hands #Call the hand tracking tool\n",
    "hands = mpHands.Hands(  \n",
    "    static_image_mode=False, #Image or Video (True: still image, False: steam mode)\n",
    "    #model_complexity=0,#0->compact model(fast speed)，1->full mode(slow speed)\n",
    "    max_num_hands=2, #How many hands are allowed to be recognized\n",
    "    min_detection_confidence=0.5, #confidence for hand detection\n",
    "    min_tracking_confidence=0.5 #confidence for hand tracking\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "AngleTH=130 #threshold(TH) angle: the joint in range of motion\n",
    "def findAngleF(a,b,c):    \n",
    "    ang = math.degrees(math.atan2(c[2]-b[2], c[1]-b[1]) - math.atan2(a[2]-b[2], a[1]-b[1]))\n",
    "    if ang<0 :\n",
    "      ang=ang+360\n",
    "    if ang >= 360- ang:\n",
    "        ang=360-ang\n",
    "    return round(ang,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)\n",
    "cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)\n",
    "\n",
    "while cap.isOpened(): #Is camera open or not\n",
    "    stime=time.time()\n",
    "    ret, frame = cap.read() #read camera data\n",
    "    h, w, c = frame.shape  #get resolution(width/height) of the camera\n",
    "    frame=cv2.flip(frame,1) #flip image：-1:up and down、0: up and down, left and right、1:  left and right\n",
    "    imgRGB = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB) #convert color channel from BGR(opencv) to RGB(mediapipe)\n",
    "    results = hands.process(imgRGB) #tracking hands and get the results\n",
    "    \n",
    "    zero_xs = [-1, -1]\n",
    "    gesture = [None, None]\n",
    "    gesture_names = [\"Rock\", \"Scissors\", \"Paper\"]\n",
    "    wrist_position = [None, None]\n",
    "    \n",
    "    if results.multi_hand_landmarks: #If there is any hand available\n",
    "        for i in range(len(results.multi_handedness)): #get the numbers of detected hands\n",
    "            thisHandType=results.multi_handedness[i].classification[0].label #get properties of the detected hand          \n",
    "            thisHand=results.multi_hand_landmarks[i] #get hand label information \n",
    "            mpDraw.draw_landmarks(frame, thisHand, mpHands.HAND_CONNECTIONS) #draw tools\n",
    "            thisHandLMList = []\n",
    "            for id, lm in enumerate(thisHand.landmark): #id=number,lm=coordinate                  \n",
    "                thisHandLMList.append([id, lm.x, lm.y,lm.z])\n",
    "                hx, hy = int(lm.x * w), int(lm.y * h) #get coordinate of the joint\n",
    "                cv2.circle(frame, (hx, hy), 5, (255, 0, 0), cv2.FILLED)  #make circles with blue color\n",
    "                cv2.putText(frame,str(id),(hx,hy), cv2.FONT_HERSHEY_PLAIN, 1, (255, 0, 255), 1)\n",
    "                if id==0:\n",
    "                    cv2.putText(frame,thisHandType,(hx,hy-30), cv2.FONT_HERSHEY_PLAIN, 2, (0, 255, 0), 2)   \n",
    "                    wrist_position[i] = (hx, hy)\n",
    "            zero_xs[i] = thisHandLMList[0]\n",
    "            finger=[0,0,0,0,0]\n",
    "            if (findAngleF(thisHandLMList[0],thisHandLMList[3],thisHandLMList[4])>AngleTH):\n",
    "                finger[0]=1\n",
    "            if (findAngleF(thisHandLMList[0],thisHandLMList[6],thisHandLMList[8])>AngleTH):\n",
    "                finger[1]=1\n",
    "            if (findAngleF(thisHandLMList[0],thisHandLMList[10],thisHandLMList[12])>AngleTH):\n",
    "                finger[2]=1\n",
    "            if (findAngleF(thisHandLMList[0],thisHandLMList[14],thisHandLMList[16])>AngleTH):\n",
    "                finger[3]=1\n",
    "            if (findAngleF(thisHandLMList[0],thisHandLMList[18],thisHandLMList[20])>AngleTH):\n",
    "                finger[4]=1\n",
    "            #print(finger)\n",
    "\n",
    "            #-----------------Recognizing hand gestures------------------------\n",
    "            text=0#     Thumb,Index,Middle,Ring,Little finger\n",
    "            if (finger==[0,0,0,0,0]):\n",
    "                text=0\n",
    "            if (finger==[0,1,1,0,0]):\n",
    "                text=1\n",
    "            if (finger==[1,1,1,1,1]):\n",
    "                text=2\n",
    "            #           Image   text   coordinate       font style   font size   font color  thickness\n",
    "            # cv2.putText(frame, textx, (0, 200), cv2.FONT_HERSHEY_PLAIN, 5  , (255, 0, 0), 5) #put text to the screen\n",
    "            gesture[i] = text\n",
    "            if wrist_position is not None:\n",
    "                cv2.putText(frame, gesture_names[text], (wrist_position[i][0] - 40, wrist_position[i][1] + 60), cv2.FONT_HERSHEY_PLAIN, 3, (0, 255, 255), 3)\n",
    "\n",
    "\n",
    "    if zero_xs[0] != -1 and zero_xs[1] != -1 :\n",
    "        # two hands are detected\n",
    "        if zero_xs[0] > zero_xs[1]:\n",
    "            gesture[0], gesture[1] = gesture[1], gesture[0]\n",
    "\n",
    "        if gesture[0] == gesture[1]:\n",
    "            cv2.putText(frame, \"draw\", (0, 200), cv2.FONT_HERSHEY_PLAIN, 5  , (255, 0, 0), 5) #put text to the screen\n",
    "        elif (gesture[0] + 1) % 3 == gesture[1]:\n",
    "            cv2.putText(frame, \"left win!\", (0, 200), cv2.FONT_HERSHEY_PLAIN, 5  , (255, 0, 0), 5) #put text to the screen\n",
    "        else:\n",
    "            cv2.putText(frame, \"right win!\", (0, 200), cv2.FONT_HERSHEY_PLAIN, 5  , (255, 0, 0), 5) #put text to the screen\n",
    "\n",
    "    etime=time.time()\n",
    "    fps=round(1/(etime-stime),2)\n",
    "    cv2.putText(frame,\"FPS:\" + str(fps),(10,50), cv2.FONT_HERSHEY_PLAIN, 3, (0, 0, 255), 3)\n",
    "    cv2.imshow('Webcam',frame) #display results on the screen\n",
    "    key=cv2.waitKey(1) #waitting for user's inputs\n",
    "    if key==ord('a'):   # 'a': capture photo\n",
    "        cv2.imwrite('webcam.jpg',frame) # save file\n",
    "    if key==ord('q'):  #'q': quit\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mocap",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
